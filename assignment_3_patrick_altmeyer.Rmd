---
title: "Problem Set 3"
author: "Patrick Altmeyer"
date: "`r format(Sys.Date(), '%d %B, %Y')`"
output: 
  bookdown::pdf_document2:
    toc: false
    number_sections: false
  bookdown::html_document2:
    code_folding: show
    number_sections: false
    toc: true
    toc_float: true
bibliography: bib.bib
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE)
library(data.table)
library(reticulate)
```

# Problem 9

# Problem 10

# Problem 11

# Problem 12

```{r}
gen_data <- function(n, d) {
  X <- matrix(runif(n=n*d,min=-2^(1/d),max=2^(1/d)), nrow=n)
  y <- as.numeric(sapply(1:n, function(i) {!any(X[i,]<(-1) | X[i,]>1)}))
  return(list(X=X,y=y))
}
```

```{python}
import numpy as np
class SmallestCubeClassifier():
  def __init__(self):
    pass
  def fit(self,X,y):
    if type(y) is not np.ndarray:
      y = np.array(y)
    if type(X) is not np.ndarray:
      X = np.array(X)
    idx = np.array([i for i in range(len(y)) if y[i]==1])
    self.bounds = (np.min(X[idx,]), np.max(X[idx,]))
  def transform(self,X):
    self.predicted = np.array([int(i.all()) for i in (X >= self.bounds[0]) & (X <= self.bounds[1])])
    return self.predicted
```

```{python}
class SmallestRectangleClassifier():
  def __init__(self):
    pass
  def fit(self,X,y):
    if type(y) is not np.ndarray:
      y = np.array(y)
    if type(X) is not np.ndarray:
      X = np.array(X)
    idx = np.array([i for i in range(len(y)) if y[i]==1])
    self.bounds = [[np.min(X[idx,j]) for j in range(X.shape[1])], [np.max(X[idx,j]) for j in range(X.shape[1])]]
  def transform(self,X):
    self.predicted = np.array([int(i.all()) for i in (X >= self.bounds[0]) & (X <= self.bounds[1])])
    return self.predicted
```


```{r, eval=FALSE}
set.seed(111)
d <- round(exp(seq(2,6,length.out=10)))
n <- round(exp(seq(3,9,length.out=50)))
J <- 10 # number of independent test sets
classifier_instances <- list(
  "cube" = py$SmallestCubeClassifier(),
  "rectangle" = py$SmallestRectangleClassifier()
)
grid <- data.table(expand.grid(n=n,d=d,classifier_name=names(classifier_instances)))
output <- rbindlist(
  lapply(
    1:nrow(grid),
    function(i) {
      list2env(c(grid[i,]), envir = environment())
      performance <- rbindlist(
        lapply( # loop over J samples 
          1:J,
          function(j) {
            train <- gen_data(n,d) # training data 
            X_train <- train[["X"]]
            y_train <- train[["y"]]
            test <- gen_data(n,d) # test data (same size)
            X_test <- test[["X"]]
            y_test <- test[["y"]]
            # Classify:
            classif <- classifier_instances[[classifier_name]]
            classif$fit(X_train, y_train) # fit
            predicted <- classif$transform(X_test) # test
            error <- sum(predicted!=y_test)/length(y_test)
            performance <- data.table(
              n = n,
              j = j,
              d = d,
              error = error,
              classif = classifier_name
            )
            return(performance)
          }
        )
      )
      # message("Done with:")
      # message(c(grid[i,]))
      return(performance)
    }
  )
)
saveRDS(output, file="data/erm.rds")
```

```{r prob-error, fig.height=4, fig.width=10, fig.cap="Probability of error of the two classifiers for different sample sizes and dimensions."}
library(ggplot2)
output <- readRDS(file="data/erm.rds")
ggplot(data=output[,.(prob_error=mean(error)),by=.(classif,n,d)], aes(x = n, y=prob_error, colour=factor(d))) +
  geom_line() +
  scale_color_discrete(name="Dimension:") +
  scale_linetype_discrete(name="Classifier:") +
  labs(
    x="Sample size",
    y="Probability of error"
  ) + 
  facet_grid(
    cols = vars(classif)
  )
```

